{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest CoverType 2b): PyTorch TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.estimator import PyTorch as PyTorchEstimator\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "# Local Dependencies:\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket_name\n",
    "%store -r experiment_name\n",
    "%store -r preproc_trial_component_name\n",
    "\n",
    "bucket = boto3.resource(\"s3\").Bucket(bucket_name)\n",
    "role = sagemaker.get_execution_role()\n",
    "smclient = boto3.client(\"sagemaker\")\n",
    "smsess = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_trial = Trial.create(\n",
    "    trial_name=util.append_timestamp(\"tabnet-pytorch\"), \n",
    "    experiment_name=experiment_name,\n",
    "    sagemaker_boto_client=smclient,\n",
    ")\n",
    "tabnet_trial.add_trial_component(preproc_trial_component_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"model-type\": \"classification\",\n",
    "    \"target\": \"Cover_Type\",\n",
    "    \"seed\": 1337,\n",
    "    \"n-d\": 64,\n",
    "    \"n-a\": 64,\n",
    "    \"n-steps\": 5,\n",
    "    \"lr\": 0.02,\n",
    "    \"gamma\": 1.5,\n",
    "    \"n-independent\": 2,\n",
    "    \"n-shared\": 2,\n",
    "    #\"cat-idxs\": \",\".join(map(lambda i: str(i), cat_idxs)),\n",
    "    # cat-dims???\n",
    "    #\"cat-emb-dim\": \",\".join(map(lambda i: str(i), cat_emb_dim)),\n",
    "    \"lambda-sparse\": 1e-4,\n",
    "    \"momentum\": 0.3,\n",
    "    \"clip-value\": 2.,\n",
    "    \"max-epochs\": 1000,\n",
    "    \"patience\": 100,\n",
    "    \"batch-size\": 16384,\n",
    "    \"virtual-batch-size\": 256,\n",
    "}\n",
    "\n",
    "\n",
    "estimator = PyTorchEstimator(\n",
    "    role=role,\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"src\",\n",
    "    framework_version=\"1.4\",\n",
    "\n",
    "    base_job_name=\"forestcover-tabnet\",\n",
    "\n",
    "    debugger_hook_config=False,\n",
    "\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.p3.2xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=[\n",
    "        # One console log per output e.g.:\n",
    "        # | EPOCH | train | valid | total time (s)\n",
    "        # | 1 | 0.58782 | 0.06811 | 25.5\n",
    "        # Since these rows are a bit brusque, we'll write quite precise/picky regexs to stay safe:\n",
    "        # TODO: Extraction not working?\n",
    "        { \"Name\": \"train:accuracy\", \"Regex\": r\"\\| +\\d+ +\\| +(.*?) +\\| +[^\\s]+ +\\| +[^\\s]+\", },\n",
    "        { \"Name\": \"validation:accuracy\", \"Regex\": r\"\\| +\\d+ +\\| +[^\\s] +\\| +(.*?)+ +\\| +[^\\s]+\", },\n",
    "    ],\n",
    "    enable_sagemaker_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    inputs={\n",
    "        \"train\": f\"s3://{bucket_name}/data/train.csv\",\n",
    "        \"validation\": f\"s3://{bucket_name}/data/validation.csv\",\n",
    "    },\n",
    "    experiment_config={\n",
    "        # This will create a TrainingJob-linked TrialComponent and automatically attach hyperparameters etc\n",
    "        \"TrialName\": tabnet_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"Training\",\n",
    "    },\n",
    "    #wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "model = PyTorchModel(\n",
    "    name=\"tabnet-3\",\n",
    "    model_data=model_path,\n",
    "    role=role,\n",
    "    source_dir=\"src/\",\n",
    "    entry_point=\"src/inference.py\",\n",
    "    framework_version=\"1.4\"\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    endpoint_name=\"tabnet-3\",\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load df_raw_test\n",
    "X_test = df_raw_test.drop(\"Cover_Type\", axis=1).to_numpy()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "s = io.StringIO()\n",
    "df_raw_test.drop(\"Cover_Type\", axis=1)[0:10].to_csv(s, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(df_raw_test.drop(\"Cover_Type\", axis=1).iloc[0:10].to_numpy())\n",
    "# yields numpy array of ints (no confidence scores!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
